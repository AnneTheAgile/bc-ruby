C:\Users\amoroney\amPrjs\rmtry\doc\zRubyRspecTips.txt
e
===========================================================
.[]WIN use BAT, eg irb.bat 


===========================================================
.[]LET vs BEGIN
===========================================================
.[]cf Rspec file. Ended up using method instead to do computation setups. 140115m.

===========================================================
.[]

=> 0
irb#1(main):031:0> "70" % "6"
=> "70"
irb#1(main):032:0> 5%2
=> 1
irb#1(main):033:0> (5-5%2)*2
=> 8
irb#1(main):034:0> (5-5%2) + 5*(5%2)
=> 9
irb#1(main):035:0> 5 - 5%2
=> 4
irb#1(main):036:0> #nbr batches
irb#1(main):037:0*
irb#1(main):038:0* q
NameError: undefined local variable or method `q' for main:Object
        from (irb#1):38
irb#1(main):039:0> get = 5
=> 5
irb#1(main):040:0> disc=2
=> 2
irb#1(main):041:0> leftover = get%disc
=> 1
irb#1(main):042:0> batches_of_cheap = (get - leftover)/disc
=> 2
irb#1(main):043:0> price = disc*batches_of_cheap
===========================================================
.[]MISC
===========================================================
.[]RSPEC-TIP; common error from syntax failure within one's spec.rb file is "No tests were found."


===========================================================
.[]MAP FIND
===========================================================
.[]Ruby-tip; find_all returns a list , so need to open up the list to find maps inside if started with array of maps.
ary = [{:id=>"a", :price=>100, :numberForBatchDiscount=>0, :batchPrice=>0},{:id=>"b", :price=>200, :numberForBatchDiscount=>2, :batchPrice=>2}]



===========================================================
IRB WIN
==========================================================
1.[]BUG; when try to paste into irb like i do in mac, win freeze on cygwin
==========================================================
31.[]Ruby-tip; Win; irb.bat --prompt-mode simple
52.[]Ruby-tip; WIN; To avoid weird Rails/Irb prompt, use option; --prompt prompt-mode (--prompt-mode prompt-mode) Switch prompt mode. Predefined prompt modes are default, simple, xmp, and inf-ruby. ; X.Interactive Ruby (irb)
http://www.tutorialspoint.com/ruby/interactive_ruby.htm
Interactive Ruby (irb)

==========================================================
53.[] ; X.Rails console runs without prompt - Stack Overflow
http://stackoverflow.com/questions/11221345/rails-console-runs-without-prompt
Rails console runs without prompt - Stack Overflow
 5 down vote accepted
	

Most probably somewhere in you ~/.irbrc, you're doing:

IRB.conf[:PROMPT_MODE] = :XMP

Try removing that line. Or change it to:

IRB.conf[:PROMPT_MODE] = :SIMPLE
==========================================================
54.[]MSG that i saw on windows irb, along with no prompt; but this is a prj for jruby ; X.Theine console freezes with 'Switch to inspect mode.' · Issue #2 · mrbrdo/theine
https://github.com/mrbrdo/theine/issues/2
Theine console freezes with 'Switch to inspect mode.' · Issue #2 · mrbrdo/theine
 BartlomiejSkwira opened this issue 3 months ago
Theine console freezes with 'Switch to inspect mode.'
No milestone
No one is assigned

I'm trying to use Theine with my setup: TorqueBox 2.3.1, jRuby 1.7.4, Rails 3.2.14 on a Ubuntu 12.04 (Vagrant located). The gem is installed in the system, the server starts with theine_server:

(spawn 11001)  
(spawn 11002)                                                                    
+ worker 11001

When I do theine console it freezes with:

Waiting for Theine worker.........................................................
Loading development environment (Rails 3.2.14)
Switch to inspect mode.

Nothing happens

==========================================================
55.[] ; X.Quick Start Guide for those more experienced with Windows
http://cygwin.com/cygwin-ug-net/ov-ex-win.html
Quick Start Guide for those more experienced with Windows
 Developers coming from a Windows background will be able to write console or GUI executables that rely on the Microsoft Win32 API instead of Cygwin using the mingw32 or mingw64 cross-compiler toolchains. The -shared option to GCC allows to write Windows Dynamically Linked Libraries (DLLs). The resource compiler windres is also provided. 
==========================================================
56.[] ; X.chmod - Wikipedia, the free encyclopedia
http://en.wikipedia.org/wiki/Chmod
chmod - Wikipedia, the free encyclopedia


$ ls -l findPhoneNumbers.sh
-rwxr-xr--  1 dgerman  staff  823 Dec 16 15:03 findPhoneNumbers.sh
$ stat -c %a findPhoneNumbers.sh
754

The r, w, and x specify the read, write, and execute access, respectively. This script can be read, written to, and executed by the user, read and executed by other members of the staff group and can also be read by others.
==========================================================
57.[] ; X.Ruby Programming/Interactive Ruby - Wikibooks, open books for an open world
http://en.wikibooks.org/wiki/Ruby_Programming/Interactive_Ruby
Ruby Programming/Interactive Ruby - Wikibooks, open books for an open world
Cygwin users

If you use Cygwin's Bash shell on Microsoft Windows, but are running the native Windows version of Ruby instead of Cygwin's version of Ruby, read this section.

To run the native version of irb inside of Cygwin's Bash shell, run irb.bat.

By default, Cygwin's Bash shell runs inside of the Windows console, and the native Windows version of irb.bat should work fine. However, if you run a Cygwin shell inside of Cygwin's rxvt terminal emulator, then irb.bat will not run properly. You must either run your shell (and irb.bat) inside of the Windows console or install and run Cygwin's version of Ruby.
===========================================================
.[]RQ; Dependency Injection
==========================================================
55.[]The constructor is the definition of what dependencies a type requires. ; X..NET Junkie - Dependency Injection anti-pattern: multiple constructors
http://www.cuttingedge.it/blogs/steven/pivot/entry.php?id=97
.NET Junkie - Dependency Injection anti-pattern: multiple constructors


.NET Junkie
Weblog of a workaholic
Print
01 June 13
Dependency Injection anti-pattern: multiple constructors
When Dependency Injection is applied correctly and completely it is important that each type only has one constructor - multiple constructors are redundant, make your DI configuration fragile, and lead to maintainability issues.

From a dependency injection perspective, our applications have two kinds of types: newables and injectables. Newables are classes that the application news up manually using the ‘new’ keyword. This is true for types such as primitives, entities, DTOs, view models and messages. Newables contain little to no logic and application code can safely depend on their implementation; there is no need to hide them behind an abstraction.

Injectables are the types that contain the logic of our application. Injectables are usually placed behind abstractions and their consumers will depend on these abstractions and not the implementations. This allows these types to be replaced, decorated, intercepted and mocked. When using dependency injection, injectables are configured in the start-up path of our application; the Composition Root. A DI framework resolves, injects and manages the injectables for us.

Let me be clear: I don’t care how many constructors your newables have. Any number that works for you is fine with me (or at least as far as this post is concerned). What I care about is how many constructors your injectables have:

An injectable should have a single constructor.

All the dependencies that an injectable has (i.e. cannot live without) should be placed in the constructor. This makes it easy to spot a type’s dependencies. This holds for both the person reading the code and the DI framework.

The constructor is the definition of what dependencies a type requires.

When we view the constructor as the definition of the required dependencies, what does it mean to have multiple constructors? In that situation the type has multiple definitions of what it requires, which is awkward to say the least. Violating the one-constructor convention leads to ambiguity; ambiguity leads to maintainability issues.

This alone should be reason enough to have a single constructor, but DI containers increase this ambiguity even more, by each having their own unique way of selecting the most appropriate constructor. These frameworks analyze the constructor and automatically inject the dependencies into them; a process called auto-wiring.

DI Container constructor resolution can be divided into three groups:

    Group 1: The container tries to prevent ambiguity by disallowing constructor resolution by default. If a type has multiple public constructors an exception is thrown.
    Group 2: The container selects the constructor with the most parameters. If this constructor contains dependencies that cannot be resolved an exception is thrown.
    Group 3: The container selects the constructor with the most parameters from the list of constructors where all of the parameters can be resolved by the container. When resolving a service the container checks the configuration to see which dependencies can be resolved and selects the most appropriate constructor.

There is another difference between the various DI frameworks concerning constructor selection that can lead to even more confusion. DI frameworks behave differently when encountering multiple selectable constructors with the same number of parameters. Some containers will throw an exception while others will pick the ‘first’ constructor. What ‘first’ means is often undefined and therefore unreliable. A recompile or even an application restart could result in the selection of a different constructor.

Letting the framework pick the most suitable constructor for you based on the availability of its dependencies might sound appealing at first, but it means that a single change in your DI configuration can result in a different code path being executed at runtime. Or worse this could happen simply because the application is restarted. This flexibility makes it harder to be sure about the correctness of your application and can lead to mysterious and hard to find errors.

These reasons should be convincing enough but I repeatedly hear the same arguments for multiple constructors.
Default constructor

Some developers define a default constructor that is called directly by the application code. This parameterless constructor in turn calls into an overloaded constructor that expects the dependencies. The default constructor creates all the dependencies and passes them on to the overloaded constructor. The overloaded constructor is called by the unit tests while the default constructor is called by the application code. For example:

public class MoveCustomerHandler
    : ICommandHandler<MoveCustomerCommand>
{
    private readonly IRepository<Customer> repository;
    private readonly ILogger logger;

    public MoveCustomerHandler()
        : this(new CustomerRepository(), 
            new FileLogger())
    {
    }

    public MoveCustomerHandler(
        IRepository<Customer> repository,
        ILogger logger)
    {
        Requires.That(repository != null);
        Requires.That(logger != null);
        
        this.repository = repository;
        this.logger = logger;
    }

    public void Handle(MoveCustomerCommand command)
    {
        // TODO
    }
}

The argument is that this makes it easier to use the type (since it has a default constructor). This argument makes sense when it comes to introducing dependency injection in a legacy code base. It allows classes to be unit tested easily while allowing the legacy system to be refactored incrementally.

The downside of this approach is that the type’s dependencies are hard-wired; the Dependency Inversion Principle is violated. This approach makes the application inflexible since replacing, wrapping or intercepting any of the given dependencies can lead to sweeping changes throughout the application. This anti-pattern is known as Poor Man’s Dependency Injection (or Bastard injection). Poor man’s DI may initially seem a valuable approach to adding DI into legacy applications, but when applying the Dependency Injection pattern from the beginning such default constructor is redundant.
Optional dependencies

Another reason developers have for defining multiple constructors is to have optional dependencies. Take a look at the following code snippet:

public class MoveCustomerHandler
    : ICommandHandler<MoveCustomerCommand>
{
    private readonly IRepository<Customer> repository;
    private readonly ILogger logger;

    public MoveCustomerHandler(
        IRepository<Customer> repository,
        ILogger logger) : this(repository)
    {
        Requires.That(logger != null);
        this.logger = logger;
    }

    public MoveCustomerHandler(
        IRepository<Customer> repository)
    {
        Requires.That(repository != null);
        this.repository = repository;
    }

    public void Handle(MoveCustomerCommand command)
    {
        if (this.logger != null)
            this.logger.Log("MoveCustomerCommand");
        // TODO:
    }
}

This anti-pattern assumes we are working with the group 3 style of container (or at least assumes the container is configured to behave this way). In the example the ILogger dependency is optional (since the second constructor does not need it). When there is no registration for ILogger, a group 3 container will skip the first constructor, and select the second constructor to inject dependencies into.

At first glance this sounds reasonable; but it isn’t because

Dependencies should hardly ever be optional.

If a dependency is optional, you should ask yourself whether the class should even depend on that abstraction.

An optional dependency implies that the reference to the dependency will be null when it’s not supplied. Null references complicate code because they require specific logic for the null-case. Instead of passing in a null reference, the caller could insert an implementation with no behavior, i.e. an implementation of the Null Object Pattern. This ensures that dependencies are always available, the type can require those dependencies and the dreaded null checks are gone. This means we have less code to maintain and test. In the case that our application does not need to log information we simply register a NullLogger:

// Implementation of the Null Object pattern
public class NullLogger : ILogger
{
    void ILogger.Log(LogEntry entry)
    {
        // Do nothing.
    }
}

I know that some developers make a dependency optional and argue that they’re not interested in testing the communication between the class being tested and the dependency, but this argument raises a big red flag for me. Assuming the previous ILogger dependency, how can we not be interested to know whether the consumer logs details correctly or not? If we’re not interested why is it there? Any behavior that isn’t worth testing isn’t worth writing! If it’s not interesting then please, stop wasting your boss’s money by writing irrelevant code.

The developers that use this argument are, in reality keen to know the behavior works as expected and their argument is just used as an excuse to avoid writing the additional tests for each class that do write to the log. The argument is, in fact, a sign of a larger problem with the design of an application - it is an indication that the application’s code is hard to test which is often caused by violating the SOLID principles. Sticking with our logging example, why do all these classes log anything? Logging is a cross-cutting concern and it is better to not clutter business logic with cross cutting concerns. Cross cutting concerns can be applied using Aspect Oriented Programming (AOP) techniques such as using decorators or interception. (This has been the main theme of my blog for the last couple of years and if you have no idea what I’m talking about please take a look at this post.)

I use these patterns to apply AOP and I find very few reasons to implement class specific logging. My applications define a generic decorator for logging that can serialize any executed message. When an operation fails I have all necessary information available to analyze and replay operations later.

Developers tend to log too much and this is often because they are scared of losing error information. This fear is mostly unfounded. Ask yourself: “Do I log too much?”.
Framework types

3rd party types such as types defined by the .NET framework or NuGet packages, can be injectables that are resolved and managed by the container. Take a SqlConnection or Entity Framework’s DbContext for instance. But it is incorrect to assume that the container should auto-wire these types. Auto-wiring of 3rd party types can lead to maintainability and trust issues. Although 3rd party types are not expected to introduce breaking changes, their designers are free to add new constructors (since the .NET Framework Design Guidelines do not consider adding constructors a breaking change). Your application could suddenly fail when a constructor is added to a 3rd party type that is auto-wired by your DI container.

Prevent using your container’s auto-wiring facility when registering 3rd party types.

A DI container uses reflection at runtime to determine the correct constructor and the addition of a new constructor may lead to the container using the new constructor. If we’re lucky the application will keep working as before or the container will throw an exception (in which case we have to change the DI configuration to use the right constructor). If we’re out of luck the type is constructed and the application fails during its lifetime. This leads to fun late night debugging sessions. If a user has installed a newer version of the framework (i.e. one that is different to our local installation) we won’t even be able to reproduce the issue: nice.

Frameworks generally target a wide range of developers and rarely make their constructors DI friendly (since doing so may hinder the usability of such classes for developers that do not practice DI). On the contrary, different rules apply when it comes to design of a reusable framework. It is common for framework constructors to accept primitive values such as strings, integers, etc. Registering such framework type while relying on the container’s auto-wiring behavior can quickly lead to fragile and unreadable registrations where most (if not all) parameters are overridden with specific values. For example this is what happens when you try to auto-wire an Entity Framework DbContext class with Castle Windsor, for a constructor with just a single parameter:

container.Register(
    Component.For<DbContext>()
    .ImplementedBy<DbContext>()
    .Parameters(
        Parameter.ForKey("connectionString")
            .Eq("name=DbName")))

That’s just ugly! Why are we trying to use the container’s auto-wiring facility when we’re overriding all of the parameters anyway? All frameworks allow you to register a factory delegate that enables you to control the creation in your code. It’s much better to register such factory delegate for your 3rd party injectables. With Simple Injector this looks as follows:

container.Register<DbContext>(
    () => new DbContext("name=DbName"));

This is much simpler, more readable, and very stable, since the C# compiler resolves the constructor during compilation.

Warning: Don’t abandon auto-wiring for the injectables that our applications define. Their contract and dependencies tend to change regularly during development. Auto-wiring our injectables with a DI container saves us the labor of updating the Composition Root for each change we make to a constructor in our system.

The injectables we create are called volatile dependencies because they are subject to change. 3rd party injectables on the other hand are called stable dependencies, since they exist in a production form and we expect new versions will not introduce any breaking changes (but me can expect new constructors to be added).
Code generators

Code generators can sometimes force types to have multiple constructors. Early versions of the T4MVC for instance, had the annoying side effect of adding an extra public constructor to MVC controller types. This ambiguity would sometimes cause problems for the DI container when selecting the expected constructor. Newer versions of T4MVC resolved this issue by making the generated constructor protected.

You may not always control the code generation process or be able to change the code generator. Modifying the T4MVC template, for example, was annoying because this prevented us from updating the template from NuGet (because NuGet skips altered files). In this scenario it is better to override your container’s default constructor resolution behavior (if needed). Such a change should not affect all types that your container auto-wires:

Only change the container’s constructor resolution behavior for types that are affected by the code generator.

This prevents reintroducing the ambiguity that we so desperately wish to prevent.
Summary

    Refrain from using the Poor Man’s DI anti-pattern and avoid defining optional dependencies and thereby removing the need for multiple constructors. 
    An injectable you maintain should only have one constructor. Applying this principle can prevent ambiguity which in turn can save us from having to depend on the specific constructor overload resolution behavior of your container.
    Do not use auto-wiring when dealing with framework types.
    When working with code generation, limit overriding your container’s constructor resolution behavior to the types that are affected by the code generator.

Steven - .NET General, Architecture, C#, Dependency injection - nine comments / No trackbacks - § ¶

nine comments:

I assume that Simple Injector belongs to Group 1?
Daniel Hilgarth (URL) - 14 06 13 - 09:39

Simple Injector is as far as I know the lonely member of Group 1. Besides these three groups there are btw a lot of lesser known frameworks and older framework versions that can't be placed in these three groups. Griffin Container for instance picks the smallest constructor, and older versions of Ninject pick the default constructor if available or fallback to the greediest constructor.
Steven (URL) - 14 06 13 - 10:05

Specially interesting, Steve. It has helped me to validate some of my thoughts about Dependency Injection.

Thanks for writing those great articles!
Regards,

@SuperJMN
José Manuel (URL) - 25 06 13 - 13:21

Hi Steven, what about having an abstract factory as constructor parameter? This makes it much easier for unit testing (with mocking).
Marc Gruben - 01 09 13 - 23:28

Mark, using an abstract factory is fine, as long as you really use an abstract factory, not an Abstract Service Locator (see: http://blog.ploeh.dk/2010/02/03/ServiceL..).
Steven (URL) - 02 09 13 - 13:00

What about two constructors where one constructor is all the required dependencies and the other takes in the dependency resolver. like so:

public class MoveCustomerHandler {
private readonly IMessageBus messageBus;
public MoveCustomerHandler(IDependencyResolver resolver) : this(resolver.Resolve<IMessageBus>()) { }
public MoveCustomerHandler(IMessageBus messageBus) { this.messageBus = messageBus; }
}

This has some added benefit when hooking up implementations to your IoC container because the dependency graph will just need your dependency resolver.
Evan Larsen (URL) - 16 12 13 - 19:09

@Evan,

This is still the service locator anti-pattern, with all the downsides that it has. Calling this dependency resolver while calling the second constructor is exactly the same thing as calling it within the body of the constructor. Since the container will detect all dependencies a class has by looking at its constructor, it doesn't help when injecting an IDependencyResolver. It even disables all sorts of optimizations a DI container can do for you, such as performance optimizations, features like context based injection and the per-graph lifestyle, and effectively renders the container blind, since it disables the possibility for the container to analyze the object graph. This means that you kill diagnostic support (example: http://bit.ly/1994Kvl) if your container has such a thing.

So seriously: don't do it!
Steven (URL) - 16 12 13 - 19:32

I just got bit by this, and I can understand the reasoning - but - I'm working some tests using Effort (https://effort.codeplex.com/), and it needs to add a second constructor to my EF database context classes, for use only in testing. And I think that is a valid counter-example to this anti-pattern.

Every time I inject a database context into my application, I use one constructor. But when I inject one into my test framework, I need to use a different one.
Jeff Dege - 31 12 13 - 17:33

Hi Jeff,

You didn't find a counter-example, since both Entity Framework and Effort are external tools and I described this in the "Framework Types" section.
Steven (URL) - 31 12 13 - 18:16

No trackbacks:

Trackback link:
Click to generate a trackback url
Note: generated url valid for only 15 minutes and javascript is required!

			
Name:   		
Remember personal info?
Yes
No
Email: 	
URL: 	
Comment: 	/

Before sending a comment, you have to answer correctly a simple question everyone knows the answer to. This completely baffles automated spam bots.
give the sum of the following numbers: 200, 30 and 4  
  (Register your username / Log in)

Notify: 		Yes, send me email when someone replies.
Hide email: 		Yes, hide my email address.

Small print: All html tags except <b> and <i> will be removed from your comment. You can make links by just typing the url or mail-address.

        Locations of visitors to this page 
        My Stack Overflow profile 
        Follow me on Twitter 
    Archives
        01 Jun - 30 Jun 2013
        01 Mar - 31 Mar 2013
        01 Aug - 31 Aug 2012
        01 Jul - 31 Jul 2012
        01 Apr - 30 Apr 2012
        01 Dec - 31 Dec 2011
        01 Oct - 31 Oct 2011
        01 Jun - 30 Jun 2011
        01 May - 31 May 2011
        01 Mar - 31 Mar 2011
        01 Nov - 30 Nov 2010
        01 Oct - 31 Oct 2010
        01 Sep - 30 Sep 2010
        01 Aug - 31 Aug 2010
        01 Jun - 30 Jun 2010
        01 May - 31 May 2010
        01 Apr - 30 Apr 2010
        01 Mar - 31 Mar 2010
        01 Feb - 28 Feb 2010
        01 Jan - 31 Jan 2010
        01 Nov - 30 Nov 2009
        01 Oct - 31 Oct 2009
        01 Sep - 30 Sep 2009
        01 Aug - 31 Aug 2009
        01 May - 31 May 2009
        01 Apr - 30 Apr 2009
        01 Jan - 31 Jan 2009
        01 Dec - 31 Dec 2008
        01 Nov - 30 Nov 2008
        01 Sep - 30 Sep 2008
        01 Aug - 31 Aug 2008
        01 Jul - 31 Jul 2008
        01 Jun - 30 Jun 2008
        01 May - 31 May 2008
        01 Apr - 30 Apr 2008
        01 Feb - 29 Feb 2008
        01 Nov - 30 Nov 2007
        01 Jun - 30 Jun 2007
        01 Mar - 31 Mar 2007
        01 Feb - 28 Feb 2007
        01 Dec - 31 Dec 2006
        01 Nov - 30 Nov 2006
        01 Oct - 31 Oct 2006
        01 Sep - 30 Sep 2006
        01 Aug - 31 Aug 2006
        01 Jul - 31 Jul 2006
        01 May - 31 May 2006

© 2007-2014 Steven van Deursen.
XML: RSS Feed XML: Atom Feed

==========================================================
51.[]i += object.anotherobject.addvalue; //violation of Law of Demeter you find an opportunity to choose to abstract. or  hints that I might want to dependency inject anotherobject; X.Ruby Best Practices- Issue #23: SOLID Design Principles
http://blog.rubybestpractices.com/posts/gregory/055-issue-23-solid-design.html
Ruby Best Practices- Issue #23: SOLID Design Principles

Dependency Injection best practices and anti-patterns
up vote 24 down vote favorite
7
	

I'm relatively unskilled in Dependency Injection, and I'd like to learn some best practices and anti-patterns to use and avoid respectively when using DI.
language-agnostic dependency-injection anti-patterns
share|improve this question
	
asked Nov 5 '09 at 18:21

	
community wiki

ripper234
	
2 	 
	
I don't think "language-agnostic" helps here: different languages dictate radically different approaches - you really wouldn't want to do the same thing in C++ as, say Ruby. –  Mike Woodhouse Nov 5 '09 at 19:36
2 	 
	
Then it might be worthwhile to ask separate questions per language? Still, I imagine there are enough general patterns so a generic question is in order. –  ripper234 Nov 5 '09 at 21:19
add comment
6 Answers
active oldest votes
up vote 6 down vote
	

I really enjoyed this article regarding DI, as it's targeted towards people who don't have a ton of DI experience, or don't even know what it is.

http://mtaulty.com/CommunityServer/blogs/mike%5Ftaultys%5Fblog/archive/2009/08/10/rough-notes-on-unity.aspx

    What’s Unity?

    It’s a “dependency injection container”.

    Now, at that point a bunch of folks reading this will say “Yes, we know and we’re already using it for reasons A, B, C or we’ve elected not to use it for reasons X,Y,Z ” and I imagine a bunch of other folks might say;

    “Huh? What’s a dependency injection container?”

    This post is for the latter people – it’s not meant to be exhaustive but hopefully it’s not completely unhelpful either :-)

share|improve this answer
	
answered Nov 5 '09 at 19:39

	
community wiki

Samuel Meacham
	add comment
up vote 3 down vote
	

There's a best practices section in Guice's user's guide.
share|improve this answer
	
answered Nov 6 '09 at 1:55

	
community wiki

Jesse Wilson
	add comment
up vote 2 down vote
	

In my opinion, Dhanji Prasanna's book Dependency Injection is a must read for software designers, both beginners and experts. It deals directly with your DI questions.
share|improve this answer
	
answered Nov 5 '09 at 19:13

	
community wiki

jnorris
	
1 	 
	
Another great book is Dependency Injection in .NET from Mark Seemann. –  Steven Jul 2 '13 at 8:04
add comment
up vote 1 down vote
	

I've found that when I see a violation of the Law of Demeter that is a hint that I might want dependency injection.

For example:

void doit()
{
    i += object.anotherobject.addvalue; //violation of Law of Demeter
}

Sometimes hints that I might want to dependency inject anotherobject.
share|improve this answer
	
answered Nov 5 '09 at 18:33

	
community wiki

Alex B
	
	 
	
Seems a little arbitrary... –  Robert Harvey♦ Nov 5 '09 at 19:49
2 	 
	
This makes some sense, though is a bit of a leap, and is incomplete. If you find a violation of the law of demeter, you find an opportunity to choose to abstract. Any time you abstract, you have an opportunity to choose to inject the dependency rather than create it yourself. So this is an indicator, but only just. There are potentially more opportunities to abstract than just this, and it might be useful to avoid DI in places where it costs more to implement than you could possibly get out of it. Still, +1 though. –  Merlyn Morgan-Graham May 2 '11 at 9:59
add comment
up vote 0 down vote
	

My basic rule about when to use DI is that I will inject between layers, so between my controller and the dao would be a layer, so I can inject, so that if I want to mock out a layer I can.

I think using DI within the same layer is not a good idea mainly because the layer should be tightly coupled, as they are related, unless you have a user story that makes it useful.

For example, if your DAO is may be on separate computers then you may need to be able to pretend that they are one layer, but use DI to actually switch between all on one machine and separate machines. Then the developer can do everything on one machine and it should work on separate machines.

But, unless there is some pressing need, I think DI within the same layer is an unnecessary complication.
share|improve this answer
	
answered Nov 5 '09 at 18:40

	
community wiki

James Black
	
2 	 
	
Well using dependency injection within a layer you will re-use existing component instances, conserving resources. Also I would say you are fostering good programming habits by forcing a modular design. –  Christoffer Soop Nov 5 '09 at 21:29
	 
	
I just see it getting more complicated than it needs to be, but that depends on what is on the layer. I tend to just do it between layers, but that is why I explained why doing it between a layer can be helpful, just not something I will suggest. –  James Black Nov 5 '09 at 21:37
add comment
up vote 0 down vote
	

Here's a dependency injection anti-pattern: Multiple Constructors.
share|improve this answer
	
answered Jul 2 '13 at 8:03 
==========================================================
52.[] ; X.language agnostic - Dependency Injection best practices and anti-patterns - Stack Overflow
http://stackoverflow.com/questions/1682551/dependency-injection-best-practices-and-anti-patterns
language agnostic - Dependency Injection best practices and anti-patterns - Stack Overflow

==========================================================
53.[] counter to another Java-derived principle to only mock types you own.  Ruby. We can have the clarity and simplicity of hard coded references and still be able to easily test them, as shown [dup] ; X.Dependency injection is not a virtue in Ruby (DHH)
http://david.heinemeierhansson.com/2012/dependency-injection-is-not-a-virtue.html
Dependency injection is not a virtue in Ruby (DHH)

Dependency injection is not a virtue

By David Heinemeier Hansson on Jan 6, 2013

In languages less open than Ruby, hard-coded class references can make testing tough. If your Java code has Date date = new Date(); buried in its guts, how do you set it to a known value you can then compare against in your tests? Well, you don't. So what you do instead is pass in the date as part of the parameters to your method. You inject the dependency on Date. Yay, testable code!

As has unfortunately happened with a variety of patterns that originate from rigid languages like Java, Dependency Injection has spread and been advocated as a cross-language best practice on trumped up benefits of flexibility and malleability. If your code never knows exactly who it's talking to, it can talk to anyone! Testing stubs, mocks, and future collaborators. Hogwash.

Ruby is like Play-Doh not LEGO and the ways it'll bend to extract the best of hard coding is truly impressive. Take the publish! example from Adam Keys' Design for test vs design for API:

def publish!
  self.update published_at: Time.now
end

In less open languages that's an obvious problem to test. But in Ruby it couldn't be easier:

Time.stub(:now) { Time.new(2012, 12, 24) }
article.publish!
assert_equal 24, article.published_at.day

This pattern is so useful that Travis Jeffrey wrapped it up in the popular Timecop gem. But if you've acquired a design taste for the Java-friendly pattern of dependency injection, it looks gross. It's a gut reaction trained on pattern matching. The brain goes HARD CODE ALERT! HARD CODE ALERT! That's the danger with patterns: they can quickly graduate from tool to taste.

Adam Keys' goes on to put forward a fine argument of whether you're designing for your tests or your API (and Lloyd Kupchanko also shared some wise words on how the API suffers from DI). I don't think there's actually much of a dichotomy between the two in a language like Ruby. We can have the clarity and simplicity of hard coded references and still be able to easily test them, as shown above.

Of course, this runs counter to another Java-derived principle to only mock types you own. Combine that with an affinity of dependency injection and the simplest thing that could possibly work is no longer not just good enough, it's disgusting. It violates the doctrine that has been so carefully assembled.

That's the real point here: Be careful with who you share your intellectual foundation with. It's fashionable to say "I'm not a Ruby programmer, I'm just a programmer". But languages shape the way we think. While we can cross-pollinate some ideas between languages, there are many we cannot. And worse, the incompatibility is not immediately apparent — especially when they both seem to just be Objective Oriented.

I'm a Ruby programmer.

==========================================================
54.[] ; X.Page not found · GitHub Pages
http://grantammons.me/2013/01/06/dependency-injection-is-not-a-bad-guy/
Page not found · GitHub Pages

===========================================================
.[]
==========================================================
1.[]Ruby-tip; DEFN: Self=class level; Plain= instance level ; X.Use of ruby self keyword? - Stack Overflow
http://stackoverflow.com/questions/6669527/use-of-ruby-self-keyword
Use of ruby self keyword? - Stack Overflow
 30 down vote
	

There are several important uses, most of which are basically to disambiguate between instance methods, class methods, and variables.

First, this is the best way to define class methods. IE:

class Foo
  def self.bar
    "class method bar"
  end

  def bar
    "instance method bar"
  end
end

Foo.bar  #returns "class method bar"

foo = Foo.new
foo.bar #returns "instance method bar"

Also, within instance methods self refers to the instance, within class methods it refers to the class, and it can always be used to distinguish from local variables.

class Bar
  def self.foo
    "foo!"
  end

  def baz
    "baz!"
  end

  def self.success
    foo #looks for variable foo, doesn't find one, looks for class method foo, finds it, returns "foo!"
  end

  def self.fail
    baz #looks for variable baz, doesn't find one, looks for class method baz, doesn't find one, raises exception
  end

  def instance_success
    baz #looks for variable baz, doesn't find one, looks for instance method baz, finds it, returns "baz!"
  end

  def instance_fail
    foo #looks for variable foo, doesn't find one, looks for instance method foo, doesn't find one, raises exception
  end

  def local_variable
    baz = "is my favorite method"
    baz #looks for variable baz, finds it, returns "is my favorite method"
  end

  def disambiguate
    baz = " is my favorite method"
    self.baz + baz #looks for instance method baz, finds it, looks for local variable baz, finds it, returns "baz! is my favorite method"
  end
end

So, in the end, you can avoid using self in many cases, but it's often helpful to go ahead and use it to make sure that you don't inadvertently create naming conflicts later on. Sometimes those can create bugs that are very hard to find. In the end it's often a matter of personal style.

Update: As noted in the comments, one more really important thing:

In a class, if you have a method like this:

def bar=(string)
  ...
end

And in another method you call:

def other_method
  bar = "abcd"
end

It isn't going to call your bar= method, it's going to create a local variable bar. So, in this case you use self to tell ruby not to create a local variable, like so:

def other_method
  self.bar = "abcd"
end

The same thing applies if you want to take an argument with the name of a method, like so:

def example
  ...
end

def other_thing(example)
  self.example(example)
end

If you left off self it would assume you meant the local variable with the same name.

So, in general, self in method names is used to distinguish between class and instance variables, and everywhere else you use it when Ruby needs help distinguishing between method calls and local variables or local variable assignment.

I hope that makes sense!
share|improve this answer
	
edited Aug 18 '13 at 0:14

	
answered Jul 12 '11 at 21:21
Andrew
12.1k1370165
	
2 	 
	
This is a more thorough answer, except that it doesn't include the assignment caveat. There is also a good blog article on the usages: jimmycuadra.com/posts/self-in-ruby which includes, specifically, assignment. You can't call an assignment method without using self (as noted in the first answer). –  mltsy Mar 11 '13 at 19:54 
===========================================================
.[]rspec new syntax
http://teaisaweso.me/blog/2013/05/27/rspecs-new-message-expectation-syntax/

With the old syntax message expectations were set like this:
foo.should_receive(:bar)
foo.should_receive(:bar).with(:buzz)
foo.should_receive(:bar).exactly(3).times

The new syntax for message expectations looks like this:
expect(foo).to receive(:bar)
expect(foo).to receive(:bar).with(:buzz)
expect(foo).to receive(:bar).exactly(3).times

This syntax also adds new ways to stub methods. Previously you may have stubbed like this:

d = double(:message1 => true)
d.stub(:message2).and_return(:value)
real_object.stub(:message).and_return(:value)

You can now stub like this:

d = double(:message1 => true)
allow(d).to receive(:message2).and_return(:value)
allow(real_object).to receive(:message).and_return(:value)

If you want to configure which syntaxes are enabled you can do so as follows (see your spec_helper.rb file):

RSpec.configure do |configuration|
  configuration.mock_with :rspec do |configuration|
    configuration.syntax = [:expect, :should]
    #configuration.syntax = :should
    #configuration.syntax = :expect
  end
end


OLD=
my error;
C:\Users\amoroney\amApps\lang\ruby\RailsInstaller\Ruby1.9.3\bin\ruby.exe -e $stdout.sync=true;$stderr.sync=true;load($0=ARGV.shift) C:\Users\amoroney\amApps\lang\ruby\RailsInstaller\Ruby1.9.3\bin/rspec C:/Users/amoroney/amPrjs/rmtry/terminal_spec.rb --require teamcity/spec/runner/formatter/teamcity/formatter --format Spec::Runner::Formatter::TeamcityFormatter
Testing started at 4:05 PM ...

RSpec::Mocks::MockExpectationError: (Double "output").puts("hi")
    expected: 1 time with arguments: ("hi")
    received: 0 times with arguments: ("hi")
./terminal_spec.rb:9:in `block (3 levels) in <module:Terminal>'

Deprecation Warnings:
Using `should_receive` from rspec-mocks' old `:should` syntax without explicitly enabling the syntax is deprecated. Use the new `:expect` syntax or explicitly enable `:should` instead. Called from C:/Users/amoroney/amPrjs/rmtry/terminal_spec.rb:9:in `block (3 levels) in <module:Terminal>'.


If you need more of the backtrace for any of these deprecations to
identify where to make the necessary changes, you can configure
`config.raise_errors_for_deprecations!`, and it will turn the
deprecation warnings into errors, giving you the full backtrace.

1 example, 1 failure, 0 passed
Finished in 0.011244 seconds
1 deprecation warning total
Process finished with exit code 1
===========================================================
.[]


